# Повторение результатов статьи 

Повторяем эксперимент из статьи

```
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., & Kohli, P. (2018). 
Leveraging grammar and reinforcement learning for neural program synthesis. 
arXiv preprint arXiv:1805.04276.
```

В статье предлагается использовать обучение с подкреплением и отсев генерируемых вариантов программ путем из их исполнения и проверки синтаксиса.

Используется сгенерированный датасет [karel_dataset](https://msr-redmond.github.io/karel-dataset/).

Исходный код для начала эксперимента доступен на [Github](https://github.com/bunelr/GandRL_for_NPS).

## Шпаргалка

См. подсказки по [сложным действиям](./FAQ.md)

## Как сдавать

 - [ ] решить задания по задачам, ответы на вопросы привести в этом файле или добавить в нужном пункте ссылку на ответ
 - [ ] оформить в виде git репозитория, в котором размещены все результаты
 - [ ] прислать ссылку на репозиторий письмом
 
Пример оформления ответа

 - как оформить ответ на вопрос?
> Например вот так
 - как добавить ответ ссылкой
> вот [ссылка](./TASK.md#как-сдавать)


Для обучения моделей можно использовать Google Colab c GPU.

## Задача 1. Подготовка данных (2 балла)

### Задание 1. (1 балл)

Получите karel_dataset, найдите в нем train.json и разберитесь в его структуре.

Вопросы
 - как правильно называется формат файла train.json?
 - как взять часть из файла train.json?
 - подготовьте файлы корректного формата размером 1%, 3%, 10% от оригинала train.json
 
### Задание 2. (1 балл)
 
Напишите код, который загружает данные из train.json
 
Вопросы
 - оцените объем необходимой RAM
 - реализуйте загрузку в итератор словарей (паттерн итератор)
  
## Задача 2. Подготовка репозитория (5 баллов)

### Задание 1. (1 балл)

Получите GandRL_for_NPS из github и смерджите его в этот репозиторий (см. [как это сделать](./FAQ.md#как-объединить-репозитории) в FAQ.md)

Вопросы
 - на каком языке реализован?
 - что нужно сделать для установки эксперимента и зависимостей?
 - где должны быть размещены данные?
 - что нужно сделать для запуска эксперимента, как указать параметры и какие значения выбрать?
 - что нужно сделать для проверки обученной модели?
 
### Задание 2. (1 балл)
 
Загрузите 1% от train.json и остальные файлы из karel_dataset
 
Вопросы
 - зачем нужны файлы *.thdump в папке датасета?
 - что содержит new_vocab?
 - где находится датасет для контроля и для теста?
 - как устроен экземпляр данных для обучения?

### Задание 3. (1 балл)

Проведите эксперимент с 1% данных

Вопросы
 - как указать вид модели?
 - какие ошибки возникли при запуске и как вы их устранили?
 - сколько эпох вы провели?
 - где сохранены результаты и логи эксперимента?
 - какого качества получен результат?
 
3а. Оператор m += 1 имеет другое значение, чем m = m + 1. Также воспользуйтесь явным приведением типов
 
3б. Из-за разных версий torch может потребоваться адаптировать код проекта. Например, для получения значения из тензора размером 1 нужно вызывать ``item()`` вместо ``[0]``

3в. Удалите кэши данных перед запуском

3г. Попробуйте заменить tqdm на progressbar2, см. [вот это сообщение](https://github.com/tqdm/tqdm/issues/613) или установить версию 2018 года.

3д. После обновления кода не забывайте установить повторно через setup.py

 
### Задание 4. (1 балл)
 
Сделайте свой клон репозитория с исправлениями, добавьте архивы подготовленных данных 1%, 3%, 10% на файлообменник с доступом по прямой ссылке
 
Вопросы
 - как получить данные по ссылке из командной строки?
 - где находится ваш репозиторий?

### Задание 5*. (1 балл)

Подключите журналирование кривых обучения и промежуточных результатов в [TensorboardX](https://github.com/lanpa/tensorboardX). 
Для этого нужно использовать SummaryWriter для сохранения промежуточных значений функции потерь внутри цикла обучения. Например, после каждого минибатча или 100 миниматчей. 

Логи сохранять в подпапку ``runs`` папки эксперимента в ``./exps/*``

Для использования установить Tensorboard и указать данную папку в качестве исходной.
  
## Задача 3. Анализ и повторение результата (3 балла)

### Задание 1. (1 балл)

Проведите эксперименты для 1%, 3%, 10% данных для MLE (supervised), RL_beam и обучаемой и предзаданной моделью синтаксиса

Вопросы
 - сколько времени заняло проведение эксперимента, какие ресурсы использовали?
 - какого качества удалось достичь?
 - приведите 10 примеров синтеза программы для karel обученной моделью

Начните с MLE и используйте обученную таким образом модель для RL в качестве начального приближения.
См. подробнее в репозитории проекта.

### Задание 2. (2 балла)

Подготовьте слайды по эксперименту: 
1. название статьи и постановка задачи (по статье, формулы) 
2. использованные данные (ссылка и как готовили)
3. постановка эксперимента (репо и команды запуска)
4. таблица с результатами (сводная)

Вопросы
 - сравните с результатами для Small dataset из статьи, удалось ли повторить их результаты?
 - как влияет выбор алгоритма контроля корректности программы на качество, в зависимости от размера?


