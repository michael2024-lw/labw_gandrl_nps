# Повторение результатов статьи 

Повторяем эксперимент из статьи

```
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., & Kohli, P. (2018). 
Leveraging grammar and reinforcement learning for neural program synthesis. 
arXiv preprint arXiv:1805.04276.
```

В статье предлагается использовать обучение с подкреплением и отсев генерируемых вариантов программ путем из их исполнения и проверки синтаксиса.

Используется сгенерированный датасет [karel_dataset](https://msr-redmond.github.io/karel-dataset/).

Исходный код для начала эксперимента доступен на [Github](https://github.com/bunelr/GandRL_for_NPS).

## Шпаргалка

См. подсказки по [сложным действиям](./FAQ.md)

## Как сдавать

 - [ ] решить задания по задачам, ответы на вопросы привести в этом файле или добавить в нужном пункте ссылку на ответ
 - [ ] оформить в виде git репозитория, в котором размещены все результаты
 - [ ] прислать ссылку на репозиторий письмом
 
Пример оформления ответа

 - как оформить ответ на вопрос?
> Например вот так
 - как добавить ответ ссылкой
> вот [ссылка](./TASK.md#как-сдавать)


Для обучения моделей можно использовать Google Colab c GPU.

## Задача 1. Подготовка данных (2 балла)

### Задание 1. (1 балл)

Получите karel_dataset, найдите в нем train.json и разберитесь в его структуре.

Вопросы
 - как правильно называется формат файла train.json?
 > JavaScript Object Notation
 - как взять часть из файла train.json?
 > При взятии части важно не создать _дополнительного_ перекоса в данных, так что выбирать элементы из датасета для создания под-сета желательно по равномерному закону распределения случайных чисел (случайно выбрать k элементов из датасета).
 >
 > Я приведу 2 простых способа. Первый - читать файл построчно, строка за строкой (в RAM, при этом, хранить не весь файл, а только некоторый _буфер_), записывая в под-сет каждую k-ую. Второй - читать не весь файл, а только его части по рассчитанным смещениям (узнать размер файла в байтах и рассчитать позиции, с которых можно начинать читать только интересующие строки), но есть заметный минус - вероятность того, что по рассчитанному смещению начинается новая строка, весьма мала, так что (чтобы не добавлять _мусор_), вероятно, в считанном буфере придётся искать знаки перехода на новую строку (2 шт., так как интересующая строка между ними). В обоих описанных случаях выборка получится неслучайной, но серьёзного перекоса, вероятно, удастся избежать, так как "пробы" будут взяты "по всех площади" датасета.
 >
 > Более сложный способ, есть шанс, что он даст результат лучше: 1) узнать размер файла; 2) сгенерировать как можно более случайные смещения (равномерное распределение) с исключением одинаковых; 3) выполнить сортировку смещений по возрастанию (чтобы кэширование IO работало эффективно); 4) читать файл датасета по сгенерированным смещениям (с поиском переводов строки и удалением _мусора_, если два смещения приводят на одну и ту же запись, взять следующую).
 - подготовьте файлы корректного формата размером 1%, 3%, 10% от оригинала train.json :white_check_mark:
 
### Задание 2. (1 балл)
 
Напишите код, который загружает данные из train.json
 
Вопросы
 - оцените объем необходимой RAM
> Объём RAM ~ data_size + data_separate_records_count * data_container_size, где data_size - размер данных для обучения (для 10% около 1 гигабайта), data_separate_records_count - количество _раздельно-хранимых_ записей (в разных экземплярах контейнера), data_container_size - средний размер служебной части контейнера. 
 - реализуйте загрузку в итератор словарей (паттерн итератор) :white_check_mark:
  
## Задача 2. Подготовка репозитория (5 баллов)

### Задание 1. (1 балл)

Получите GandRL_for_NPS из github и смерджите его в этот репозиторий (см. [как это сделать](./FAQ.md#как-объединить-репозитории) в FAQ.md)

Вопросы
 - на каком языке реализован?
> Python
 - что нужно сделать для установки эксперимента и зависимостей?
> Самый простой вариант - воссоздать окружение, которое было у экспериментатора. Коммит с кодом был сделан 16.02.2018 и он только один, значит, код был выложен уже после написания кода для эксперимента, в качестве исходников, прилагаемых к статье. Так что для запуска в оригинальной среде нужно было найти версии пакетов, доступных в пределах января 2018 или раньше, что и было сделано мной. Я установил Ubuntu 18.04 (она появилась позднее, зато это самый близкий LTS), pip для Python 2.7 и подобрал версии пакетов, при которых код работает так, как задумывал разработчик (версии пакетов теперь прописаны в setup.py: tqdm 4.64.1, numpy 1.14.0, torch 0.3.1, torchvision 0.2.0, matplotlib 2.1.2). Важно производить установку именно в том порядке, в котором пакеты перечислены, иначе pip в рамках решения зависимостей установит более новые версии, которые вызовут проблемы (setup.py не соблюдает должный порядок).
 - где должны быть размещены данные?
> В любом удобном месте, доступном для изменения пользователю, от имени которого происходит запуск. Конечно, нужно прописать соответствующий путь в командах скриптов train и evaluate.
 - что нужно сделать для запуска эксперимента, как указать параметры и какие значения выбрать?
> Нужно выполнить команды (здесь: https://github.com/michael2024-lw/labw_gandrl_nps/blob/master/README.md#evaluation), указанные авторами исходного исследования (сначала первичное обучение, затем fine-tune). Параметры я старался менять минимально. Приходилось менять их, в основном, лишь потому, что на видеокарте меньше видеопамяти, чем нужно для указанных размеров батча. Иногда при уменьшении батча тренировка переставала сходиться, и приходилось менять другие параметры, такие как rl_beam (размер лучевого поиска), nb_rollouts (число выборок для оценки градиента), число эпох и др.
 - что нужно сделать для проверки обученной модели?
> Выполнить команду eval_cmd.py на тестовой выборке. (нужная команда здесь: https://github.com/michael2024-lw/labw_gandrl_nps/blob/master/README.md#evaluation)

### Задание 2. (1 балл)
 
Загрузите 1% от train.json и остальные файлы из karel_dataset
 
Вопросы
 - зачем нужны файлы *.thdump в папке датасета?
> Они содержат кэшированные, подготовленные к использованию в обучении данные соответствующего файла датасета (тензоры torch и индексы).
 - что содержит new_vocab?
> Команды Karel (из которых будет состоять синтезируемая программа), с которыми в ходе обучения начинает ассоциироваться токен.
 - где находится датасет для контроля и для теста?
> Для контроля - ./1m_6ex_karel/val.json; Для теста - ./1m_6ex_karel/test.json.
 - как устроен экземпляр данных для обучения?
> Он состоит из нескольких обучающих примеров входов-выходов (состояния поля Karel), корректного набора токенов в нужном порядке (желаемый выход), а также абстрактного синтаксического дерева для этого набора.

### Задание 3. (1 балл)

Проведите эксперимент с 1% данных

Вопросы
 - как указать вид модели?
 - какие ошибки возникли при запуске и как вы их устранили?
 - сколько эпох вы провели?
 - где сохранены результаты и логи эксперимента?
 - какого качества получен результат?
 
3а. Оператор m += 1 имеет другое значение, чем m = m + 1. Также воспользуйтесь явным приведением типов
 
3б. Из-за разных версий torch может потребоваться адаптировать код проекта. Например, для получения значения из тензора размером 1 нужно вызывать ``item()`` вместо ``[0]``

3в. Удалите кэши данных перед запуском

3г. Попробуйте заменить tqdm на progressbar2, см. [вот это сообщение](https://github.com/tqdm/tqdm/issues/613) или установить версию 2018 года.

3д. После обновления кода не забывайте установить повторно через setup.py

 
### Задание 4. (1 балл)
 
Сделайте свой клон репозитория с исправлениями, добавьте архивы подготовленных данных 1%, 3%, 10% на файлообменник с доступом по прямой ссылке
 
Вопросы
 - как получить данные по ссылке из командной строки?
> Например, так: wget {url} (вместо "{url}" подставляется прямая ссылка на скачивание)
 - где находится ваш репозиторий?
> https://github.com/michael2024-lw/labw_gandrl_nps.git

### Задание 5*. (1 балл)

Подключите журналирование кривых обучения и промежуточных результатов в [TensorboardX](https://github.com/lanpa/tensorboardX). 
Для этого нужно использовать SummaryWriter для сохранения промежуточных значений функции потерь внутри цикла обучения. Например, после каждого минибатча или 100 миниматчей. 

Логи сохранять в подпапку ``runs`` папки эксперимента в ``./exps/*``

Для использования установить Tensorboard и указать данную папку в качестве исходной.
  
## Задача 3. Анализ и повторение результата (3 балла)

### Задание 1. (1 балл)

Проведите эксперименты для 1%, 3%, 10% данных для MLE (supervised), RL_beam и обучаемой и предзаданной моделью синтаксиса

Вопросы
 - сколько времени заняло проведение эксперимента, какие ресурсы использовали?
 - какого качества удалось достичь?
 - приведите 10 примеров синтеза программы для karel обученной моделью

Начните с MLE и используйте обученную таким образом модель для RL в качестве начального приближения.
См. подробнее в репозитории проекта.

### Задание 2. (2 балла)

Подготовьте слайды по эксперименту: 
1. название статьи и постановка задачи (по статье, формулы) 
2. использованные данные (ссылка и как готовили)
3. постановка эксперимента (репо и команды запуска)
4. таблица с результатами (сводная)

Вопросы
 - сравните с результатами для Small dataset из статьи, удалось ли повторить их результаты?
 - как влияет выбор алгоритма контроля корректности программы на качество, в зависимости от размера?


