# Повторение результатов статьи 

Повторяем эксперимент из статьи

```
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., & Kohli, P. (2018). 
Leveraging grammar and reinforcement learning for neural program synthesis. 
arXiv preprint arXiv:1805.04276.
```

В статье предлагается использовать обучение с подкреплением и отсев генерируемых вариантов программ путем из их исполнения и проверки синтаксиса.

Используется сгенерированный датасет [karel_dataset](https://msr-redmond.github.io/karel-dataset/).

Исходный код для начала эксперимента доступен на [Github](https://github.com/bunelr/GandRL_for_NPS).

## Шпаргалка

См. подсказки по [сложным действиям](./FAQ.md)

## Как сдавать

 - [ ] решить задания по задачам, ответы на вопросы привести в этом файле или добавить в нужном пункте ссылку на ответ
 - [ ] оформить в виде git репозитория, в котором размещены все результаты
 - [ ] прислать ссылку на репозиторий письмом
 
Пример оформления ответа

 - как оформить ответ на вопрос?
> Например вот так
 - как добавить ответ ссылкой
> вот [ссылка](./TASK.md#как-сдавать)


Для обучения моделей можно использовать Google Colab c GPU.

## Задача 1. Подготовка данных (2 балла)

### Задание 1. (1 балл)

Получите karel_dataset, найдите в нем train.json и разберитесь в его структуре.

Вопросы
 - как правильно называется формат файла train.json?
 > JavaScript Object Notation
 - как взять часть из файла train.json?
 > При взятии части важно не создать _дополнительного_ перекоса в данных, так что выбирать элементы из датасета для создания под-сета желательно по равномерному закону распределения случайных чисел (случайно выбрать k элементов из датасета).
 >
 > Я приведу 2 простых способа. Первый - читать файл построчно, строка за строкой (в RAM, при этом, хранить не весь файл, а только некоторый _буфер_), записывая в под-сет каждую k-ую. Второй - читать не весь файл, а только его части по рассчитанным смещениям (узнать размер файла в байтах и рассчитать позиции, с которых можно начинать читать только интересующие строки), но есть заметный минус - вероятность того, что по рассчитанному смещению начинается новая строка, весьма мала, так что (чтобы не добавлять _мусор_), вероятно, в считанном буфере придётся искать знаки перехода на новую строку (2 шт., так как интересующая строка между ними). В обоих описанных случаях выборка получится неслучайной, но серьёзного перекоса, вероятно, удастся избежать, так как "пробы" будут взяты "по всех площади" датасета.
 >
 > Более сложный способ, есть шанс, что он даст результат лучше: 1) узнать размер файла; 2) сгенерировать как можно более случайные смещения (равномерное распределение) с исключением одинаковых; 3) выполнить сортировку смещений по возрастанию (чтобы кэширование IO работало эффективно); 4) читать файл датасета по сгенерированным смещениям (с поиском переводов строки и удалением _мусора_, если два смещения приводят на одну и ту же запись, взять следующую).
 - подготовьте файлы корректного формата размером 1%, 3%, 10% от оригинала train.json :white_check_mark:
 
### Задание 2. (1 балл)
 
Напишите код, который загружает данные из train.json
 
Вопросы
 - оцените объем необходимой RAM
> Объём RAM ~ data_size + data_separate_records_count * data_container_size, где data_size - размер данных для обучения (для 10% около 1 гигабайта), data_separate_records_count - количество _раздельно-хранимых_ записей (в разных экземплярах контейнера), data_container_size - средний размер служебной части контейнера. 
 - реализуйте загрузку в итератор словарей (паттерн итератор) :white_check_mark:
  
## Задача 2. Подготовка репозитория (5 баллов)

### Задание 1. (1 балл)

Получите GandRL_for_NPS из github и смерджите его в этот репозиторий (см. [как это сделать](./FAQ.md#как-объединить-репозитории) в FAQ.md)

Вопросы
 - на каком языке реализован?
 - что нужно сделать для установки эксперимента и зависимостей?
 - где должны быть размещены данные?
 - что нужно сделать для запуска эксперимента, как указать параметры и какие значения выбрать?
 - что нужно сделать для проверки обученной модели?
 
### Задание 2. (1 балл)
 
Загрузите 1% от train.json и остальные файлы из karel_dataset
 
Вопросы
 - зачем нужны файлы *.thdump в папке датасета?
 - что содержит new_vocab?
 - где находится датасет для контроля и для теста?
 - как устроен экземпляр данных для обучения?

### Задание 3. (1 балл)

Проведите эксперимент с 1% данных

Вопросы
 - как указать вид модели?
 - какие ошибки возникли при запуске и как вы их устранили?
 - сколько эпох вы провели?
 - где сохранены результаты и логи эксперимента?
 - какого качества получен результат?
 
3а. Оператор m += 1 имеет другое значение, чем m = m + 1. Также воспользуйтесь явным приведением типов
 
3б. Из-за разных версий torch может потребоваться адаптировать код проекта. Например, для получения значения из тензора размером 1 нужно вызывать ``item()`` вместо ``[0]``

3в. Удалите кэши данных перед запуском

3г. Попробуйте заменить tqdm на progressbar2, см. [вот это сообщение](https://github.com/tqdm/tqdm/issues/613) или установить версию 2018 года.

3д. После обновления кода не забывайте установить повторно через setup.py

 
### Задание 4. (1 балл)
 
Сделайте свой клон репозитория с исправлениями, добавьте архивы подготовленных данных 1%, 3%, 10% на файлообменник с доступом по прямой ссылке
 
Вопросы
 - как получить данные по ссылке из командной строки?
 - где находится ваш репозиторий?

### Задание 5*. (1 балл)

Подключите журналирование кривых обучения и промежуточных результатов в [TensorboardX](https://github.com/lanpa/tensorboardX). 
Для этого нужно использовать SummaryWriter для сохранения промежуточных значений функции потерь внутри цикла обучения. Например, после каждого минибатча или 100 миниматчей. 

Логи сохранять в подпапку ``runs`` папки эксперимента в ``./exps/*``

Для использования установить Tensorboard и указать данную папку в качестве исходной.
  
## Задача 3. Анализ и повторение результата (3 балла)

### Задание 1. (1 балл)

Проведите эксперименты для 1%, 3%, 10% данных для MLE (supervised), RL_beam и обучаемой и предзаданной моделью синтаксиса

Вопросы
 - сколько времени заняло проведение эксперимента, какие ресурсы использовали?
 - какого качества удалось достичь?
 - приведите 10 примеров синтеза программы для karel обученной моделью

Начните с MLE и используйте обученную таким образом модель для RL в качестве начального приближения.
См. подробнее в репозитории проекта.

### Задание 2. (2 балла)

Подготовьте слайды по эксперименту: 
1. название статьи и постановка задачи (по статье, формулы) 
2. использованные данные (ссылка и как готовили)
3. постановка эксперимента (репо и команды запуска)
4. таблица с результатами (сводная)

Вопросы
 - сравните с результатами для Small dataset из статьи, удалось ли повторить их результаты?
 - как влияет выбор алгоритма контроля корректности программы на качество, в зависимости от размера?


